{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> MA Crossings </h4>\n",
    "<h5> Creating a simple 200 to 50 MA crossing simulation on jupyter. </h5>\n",
    "<h6> Will use previous bollinger band program for the simulation. </h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"Bitstamp_ETHUSD_1h.csv\"\n",
    "DATASET_HEADER = \"unix,open,high,low,close,Volume USD\"\n",
    "TX_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv():\n",
    "    '''Imports csv to pandas dataframe.'''\n",
    "    print(f\"Importing {DATASET} as df...\")\n",
    "    df = pd.read_csv(DATASET) # csv to df\n",
    "    df = df.sort_values(by=[\"date\"], ascending=True) # Sort data by ascending date\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], unit = \"s\") # Converting epoch to datetime\n",
    "    print(\"Import successful.\")\n",
    "    return df\n",
    "\n",
    "def get_sma(closing_price, SMA_PERIOD):\n",
    "    ''' Gets simple moving average with SMA_PERIOD as indicated by config.py.'''\n",
    "    return closing_price.rolling(SMA_PERIOD).mean()\n",
    "\n",
    "def check_param(df):\n",
    "    ''' Go through each data in the dataframe to look for buy and sell signals.'''\n",
    "    df.dropna(inplace=True) # Drop rows with NaNs\n",
    "    df.iloc[::-1] # Reverse index\n",
    "    prev_sig, sig, logbook = False,False, [] #F->T BUY, T->F SELL\n",
    "    # Problem: It buys the first signal as long as SMA200 is above SMA50\n",
    "    for i in df.index:\n",
    "        #print(f\"Processing {(len(df) - 1)-i} of {(len(df) - 1)}\")\n",
    "        prev_sig = sig\n",
    "        sig = False if(df['sma_200'][i] > df['sma_50'][i]) else True\n",
    "        if prev_sig != sig: transact(i, sig, logbook)\n",
    "    return logbook\n",
    "\n",
    "\n",
    "def transact(i, sig, logbook):\n",
    "    '''Buys or sells, depending on the signal'''\n",
    "    logs = {}\n",
    "    logs['datetime'] = df['date'][i]\n",
    "    logs['price'] = df['close'][i]\n",
    "    logs['size'] = TX_SIZE\n",
    "    if sig: #Buy\n",
    "        logs['type'] = \"BUY\"\n",
    "        logbook.append(logs.copy())\n",
    "        logs.clear()\n",
    "    else: #Sell\n",
    "        logs['type'] = \"SELL\"\n",
    "        logbook.append(logs.copy())\n",
    "        logs.clear()\n",
    "\n",
    "def export_csv(tx):\n",
    "    ''' Export 2 csv files - one containing sold positions and one with open positions.'''\n",
    "    with open('output.csv', 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"datetime\",\"price\", \"size\", \"type\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing btc.csv as df...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18984/2787253937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sma_200'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sma_50'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlogbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18984/127973170.py\u001b[0m in \u001b[0;36mimport_csv\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Importing {DATASET} as df...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# csv to df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Sort data by ascending date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Converting epoch to datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Import successful.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sarmi\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sarmi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6258\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6259\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6261\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sarmi\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df = import_csv()\n",
    "    df['sma_200'] = get_sma(df['close'],200)\n",
    "    df['sma_50'] = get_sma(df['close'],50)\n",
    "    logbook = check_param(df)\n",
    "\n",
    "    print(\"Calculating profits.\")\n",
    "    profit, profit_book = 0, []\n",
    "    for i in range(1,len(logbook)):\n",
    "        if i%2 == 1:\n",
    "            x = logbook[i]['price'] - logbook[i-1]['price']\n",
    "            profit += x\n",
    "            profit_book.append(x)\n",
    "    export_csv(logbook)\n",
    "    with open(\"profit_book.txt\",\"w\") as f:\n",
    "        for i in profit_book:\n",
    "            f.write(str(i)+\"\\n\")\n",
    "        f.write(f\"Total profit is {profit}\")\n",
    "    print(\"Done.\")\n",
    "    logs = pd.read_csv(\"output.csv\")\n",
    "    logs['datetime'] = pd.to_datetime(logs['datetime'])\n",
    "    # PLOTTING\n",
    "    for year in [2018,2019,2020,2021,2022]:\n",
    "        data = df[df['date'].dt.year == year] # Filter by year\n",
    "        logs_data = logs[logs['datetime'].dt.year == year] # Filter buys and sells by year\n",
    "        buys = logs_data[logs_data['type'] == \"BUY\"] # Filter by 'type' w/ string BUY\n",
    "        sells = logs_data[logs_data['type'] == \"SELL\"] # Filter by 'type' w/ string SELL\n",
    "        fig = plt.figure(figsize=(60,16)) # 60 x 16 in plot\n",
    "        ax = fig.add_subplot(111)# just 1 plot (x,y,z)\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator()) # set X axis ticks to be a month apart\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b')) # set X axis ticks format\n",
    "        plt.yticks(np.arange(0, max(data['close']),max(data['close'])/20)) # Set Y axis ticks to be evenly spaced out in 20 divisions\n",
    "        plt.title(f\"ETHUSD YEAR {year}\")\n",
    "        plt.plot(data['date'],data['close']) # plotting of date,price\n",
    "        plt.plot(data['date'],data['sma_200'],label=\"ETH 200 SMA\",color='orange', zorder=0) #plotting of sma, zorder = layer number\n",
    "        plt.plot(data['date'],data['sma_50'],label=\"ETH 50 SMA\",color='gold', zorder=10)\n",
    "        plt.scatter(buys['datetime'],buys['price'],label=\"Buys\",color='green', zorder=20, marker=\"^\", s=100) #plotting of buy signals\n",
    "        for i,j in zip(buys['datetime'],buys['price']): # zip creates a list of lists from 2 lists. zip([a,b],[1,2]) results in ([a,1],[b,2])\n",
    "            plt.text(i, j, j) # adding text\n",
    "        plt.scatter(sells['datetime'],sells['price'],label=\"Sells\",color='red', zorder=30, marker=\"v\", s=100) #plotting of sell signals\n",
    "        for i,j in zip(sells['datetime'],sells['price']):\n",
    "            plt.text(i, j, j)\n",
    "        plt.legend(loc='upper right') # Set legend location\n",
    "        plt.show()# Show the plot"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8db4b2c2b9ce4f902c3f8c43cb98d1d931f9e80c0cdcffa40b97648f504d5039"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
